基于 Transformer 的中文情感分析系统
本项目是一个针对外卖平台用户评论的情感分析系统，采用 Transformer 模型实现中文文本的情感二分类（正向 / 负向），并通过 Flask 构建 Web 交互界面，支持用户输入文本并实时获取情感分析结果。

一、项目概述
核心功能：分析外卖用户评论的情感倾向，输出 "正向" 或 "负向" 结果及对应置信度
技术栈：Python、TensorFlow/Keras、Jieba 分词、Flask、Scikit-learn、Pandas
模型架构：Transformer（含位置编码层、多头注意力机制）
适用场景：外卖平台评论情感分析、用户满意度调研、客服反馈分类等

二、数据集介绍
2.1 数据集基本信息
使用waimai_10k 数据集，为某外卖平台真实用户评论数据，共包含 10000 条有效评论：
正向评论（好评）：5000 条（label=1）
负向评论（差评）：5000 条（label=0）
数据特点：文本长度不一，包含口语化表达、标点符号及数字信息
2.2 数据字段说明
字段名	数据类型	说明
review	字符串	用户评论内容（如 "送餐很快，味道很棒"）
label	整数	情感标签（1 = 正向，0 = 负向）
2.3 数据集地址
https://raw.githubusercontent.com/SophonPlus/ChineseNlpCorpus/master/datasets/waimai_10k/waimai_10k.csv

三、项目结构
plaintext
sentiment-analysis-system/
├── data/                  # 数据集目录
│   └── waimai_10k.csv      # 原始外卖评论数据集（需手动下载或代码自动读取）
├── model/                 # 模型与相关文件保存目录（自动生成）
│   ├── Transformer.keras   # 训练完成的Transformer模型文件
│   ├── vocab.pkl           # 手动构建的词汇表（映射词语到整数索引）
│   └── label_encoder.pkl   # 标签编码器（映射情感标签与整数）
├── stopwords.txt          # 中文停用词表（过滤"的""了""在"等无意义词汇）
├── training_log.csv       # 模型训练日志（自动生成，记录loss、accuracy等指标）
├── main.py                # 项目主程序（含数据处理、模型训练、Web服务）
└── README.md              # 项目说明文档

四、核心功能模块
4.1 数据预处理模块
（1）文本清洗
中文保留：通过is_chinese()函数过滤非中文字符，仅保留中文、数字及关键标点（！、？、，、。、.、,）
停用词过滤：通过getStopWords()加载停用词表，移除无意义词汇（如 "的"" 了 ""这个"），减少噪声干扰
异常处理：解析数据时捕获格式错误、空文本等异常，跳过无效评论，保证数据质量
（2）中文分词
使用jieba.lcut()对清洗后的文本进行精准分词，示例：
输入文本："很快，好吃味道足，量大"
分词结果：["很快", "好吃", "味道足", "量大"]
（3）词汇表构建与文本序列化
词汇表构建：基于训练集评论，过滤低频词（默认最小词频≥3），构建最大容量为 8000 的词汇表，保留特殊标记：
<PAD>：用于文本长度不足时填充（统一序列长度）
<UNK>：用于未登录词（词汇表中未包含的词语）
文本序列化：通过texts_to_sequences()将分词后的文本转换为固定长度（max_len=100）的整数序列：
长度超出 100 时：截断尾部内容
长度不足 100 时：用<PAD>填充至 100
（4）数据划分与标签编码
数据划分：使用train_test_split()按 7:2:1 比例划分数据集：
训练集（70%）：用于模型参数训练
验证集（20%）：用于训练过程中调整超参数、早停判断
测试集（10%）：用于最终模型性能评估
标签编码：使用LabelEncoder()将情感标签（0/1）转换为模型可识别的整数格式（兼容二分类任务）
4.2 Transformer 模型模块
（1）模型结构设计
输入层（Input, shape=(100,)）
    ↓
嵌入层（Embedding, vocab_size→128维词向量）
    ↓
位置编码层（PositionalEncoding, 添加词序信息）
    ↓
Transformer编码器（MultiHeadAttention, 4个注意力头）
    ↓
全局平均池化层（GlobalAveragePooling1D, 聚合序列特征）
    ↓
全连接层（Dense, 64个神经元，ReLU激活）
    ↓
Dropout层（Dropout(0.5), 防止过拟合）
    ↓
输出层（Dense(1), Sigmoid激活，输出0~1概率）
（2）模型训练配置
损失函数：binary_crossentropy（二分类任务专用，计算预测概率与真实标签的交叉熵）
优化器：Adam（自适应学习率优化器，训练稳定且收敛速度快）
评估指标：accuracy（准确率，衡量整体预测正确的样本比例）
回调函数：
EarlyStopping：监控验证集val_loss，连续 10 轮无下降则停止训练，并恢复最优权重（避免过拟合）
CSVLogger：将每轮训练的loss、accuracy、val_loss、val_accuracy记录到training_log.csv
类别权重：通过compute_class_weight()计算类别平衡权重，缓解负向评论（8000 条）多于正向评论（4000 条）导致的模型偏向性
（3）模型性能评估
训练完成后，在测试集上计算以下指标评估模型效果：
混淆矩阵（Confusion Matrix）：展示真阳性（TP）、真阴性（TN）、假阳性（FP）、假阴性（FN）数量，直观反映分类错误类型
准确率（Accuracy）：整体预测正确的样本比例，公式：(TP+TN)/(TP+TN+FP+FN)
精确率（Precision）：预测为某类的样本中实际正确的比例，公式：TP/(TP+FP)（加权平均处理类别不平衡）
召回率（Recall）：实际为某类的样本中被正确预测的比例，公式：TP/(TP+FN)（加权平均处理类别不平衡）
F1 分数（F1-Score）：精确率与召回率的调和平均数，综合衡量模型性能，公式：2*(Precision*Recall)/(Precision+Recall)
4.3 Web 交互模块
（1）界面设计
通过HTML_TEMPLATE定义响应式 Web 界面，核心元素包括：
文本输入框：支持多行输入，占位提示 "请输入要分析的文本..."
分析按钮：点击后触发情感分析请求，按钮文本 "分析情感"
结果展示区：根据分析结果显示不同样式：
正向评论：绿色背景，文本 "分析结果: active"
负向评论：红色背景，文本 "分析结果: negative"
异常情况：灰色背景，文本 "请输入文本" 或 "分析出错: xxx"
置信度展示区：显示模型预测的置信度（如 "置信度: 98.52%"）
（2）Flask 路由设计
首页路由（/）：用户访问http://127.0.0.1:5000时，返回 Web 界面
分析路由（/analyze）：接收前端 POST 请求，处理流程：
解析请求中的文本数据
调用预测函数处理文本
返回 JSON 格式结果（含情感标签、置信度）
（3）预测流程
用户在 Web 界面输入文本并点击 "分析情感" 按钮
前端通过 Fetch API 发送 POST 请求到/analyze接口，携带文本数据
后端处理：
检查model/目录下是否存在预训练模型，不存在则自动触发训练
对输入文本执行预处理（清洗→分词→序列化）
调用 Transformer 模型预测情感概率，转换为 "active"（正向）或 "negative"（负向）标签
计算置信度（正向评论取预测概率，负向评论取 1 - 预测概率，保留 2 位小数）
后端返回 JSON 结果，前端更新界面展示分析结果

五、使用说明
5.1 环境准备
（1）依赖库安装
pip install numpy pandas tensorflow flask jieba scikit-learn matplotlib
（2）数据集准备
下载waimai_10k.csv数据集
将数据集放入data/目录下（若目录不存在，运行程序时会自动创建）
5.2 运行项目
执行主程序：
python main.py
系统初始化：
首次运行：因无预训练模型，会自动触发模型训练（约 5~10 分钟，取决于硬件性能）
非首次运行：直接加载model/目录下的预训练模型，无需重新训练
访问系统：打开浏览器，输入地址http://127.0.0.1:5000，进入情感分析界面
5.3 情感分析操作
在文本输入框中输入外卖评论（示例）：
正向评论："送餐很快，味道很棒，下次还点"
负向评论："菜凉了，味道很咸，不推荐"
点击 "分析情感" 按钮，等待 1~2 秒后查看结果：
正向结果：绿色背景，显示 "分析结果: active" 及置信度（如 "置信度: 96.32%"）
负向结果：红色背景，显示 "分析结果: negative" 及置信度（如 "置信度: 98.15%"）
异常情况：
未输入文本：灰色背景，显示 "请输入文本"
系统错误：灰色背景，显示 "分析出错: [错误信息]"

六、注意事项
模型训练相关：
若出现 "连续 10 轮验证集 loss 无下降" 导致早停，但模型性能未达预期，可修改EarlyStopping的patience参数（如改为 20），延长训练观察期
训练过程中生成的training_log.csv可用于分析模型收敛趋势（如 loss 是否稳定下降、是否过拟合）
数据相关：
若需更换数据集，需确保数据格式与waimai_10k.csv一致（含review和label字段），或修改getData()函数适配新数据格式
停用词表stopwords.txt可根据需求扩展（如添加行业专用无意义词汇）

